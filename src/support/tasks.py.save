import json
import logging

from django.core.mail import send_mail

from celery import shared_task
from src.support.models import EmailConfig
from src.utilities import RedisClient


@shared_task(name="send_email_notification")
def send_email_notification(redis_key) -> None:
    connection = RedisClient().connection
    cached_data = connection.get(redis_key)
    if not cached_data:
        return
    data = json.loads(cached_data)
    topic = data.get("topic")
    text = data.get("text")
    receiver = data.get("receiver")
    print(f"sending email {topic} {text} for {receiver}")
    # check for None in data
    if not text or not receiver:
        logging.warning(f"Invalid data: {text}, {receiver}")
        return
    sender_instance = EmailConfig.get_admin_sender()
    if not sender_instance:
        logging.warning("Sender not found, skipping")
        return
    connection = sender_instance.connection()
    send_mail(
        topic,
        "",
        sender_instance.address,
        [receiver],
        connection=connection,
        html_message=text,
    )
    logging.info(f"message {topic} to {receiver} sent")
=======
from src.decorators import ignore_duplicates
from src.store.models import Status, Token
from src.store.services.ipfs import get_ipfs

logger = logging.getLogger("celery")


@shared_task(name="parse_metadata_starter")
@ignore_duplicates
def parse_metadata_starter():
    """
    Periodically send tasks to parse metadata
    """
    tokens = Token.objects.filter(status=Status.IMPORTING, deleted=False).exclude(image__isnull=False)

    for token in tokens:
        process_parse_metadata.apply_async(args=(token.id,), priority=5)


@shared_task(name="process_parse_metadata")
@ignore_duplicates
def process_parse_metadata(token_id: int) -> None:
    """
    Parses token metadata and saves in DB (if not duplicate)
    """

    token = Token.objects.get(id=token_id)
    metadata_uri = get_ipfs(token.internal_id, token.collection)

    metadata_uri = metadata_uri.replace("ipfs://", "https://ipfs.io/ipfs/")

    res = requests.get(metadata_uri)
    if res.status_code != 200:
        raise Exception(f"cannot fetch metadata for uri {metadata_uri}")
    response = res.json()

    name = response.get("name")
    if name:
        if str(name).lstrip("#").isdigit():
            name = token.collection.name + str(name)
        token.name = name
    token.image = response.get("image").replace("ipfs://", "https://ipfs.io/ipfs/")
    token.animation_file = response.get("animation_url")
    token.description = response.get("description")

    attributes = response.get("attributes")
    if attributes:
        token._parse_and_save_details(attributes)

    token.status = Status.COMMITTED
    token.save()
>>>>>>> Stashed changes
